{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130622fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import draw, fill\n",
    "import pyrender\n",
    "import glob\n",
    "import trimesh\n",
    "from trimesh import remesh\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from trimesh import Trimesh\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import math\n",
    "import os\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "import skeletor as sk\n",
    "from view_data import view_mesh\n",
    "import copy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from project_statistics import get_outliers\n",
    "from create_dataset import load_dataset,dir_to_sorted_file_list\n",
    "from trimesh.repair import fill_holes\n",
    "from trimesh.points import PointCloud\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "from scipy.stats import wasserstein_distance\n",
    "from utils import*\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1a448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('normalized_scalar_features.pkl', 'rb') as f:\n",
    "    query_database = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb7d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_DIRECTORY = r\"full_normalized_benchmark\\**\\*.off\"\n",
    "mesh_files = list(glob.glob(DB_DIRECTORY,recursive=True))\n",
    "mesh_files.sort(key=natural_keys)\n",
    "mean_std = np.load('mean_std.npy')\n",
    "sampled_min_max = np.load('sampeld_min_max.npy')\n",
    "sampled_mean_std = np.load('sampeld_mean_std.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc36e7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 [221, 223, 220, 224, 229, 105]\n",
      "700 [700, 722, 1786, 721, 687, 714]\n",
      "1313 [1313, 1121, 1323, 1132, 241, 1128]\n"
     ]
    }
   ],
   "source": [
    "K = 6\n",
    "for i,mesh_file in enumerate(mesh_files):\n",
    "    features = []\n",
    "    features_df = pd.DataFrame(columns = ['id','surface_area','volume','compactness','sphericity','diameter','rectangulairty','eccentricity','curvature', 'A3', 'D1', 'D2', 'D3', 'D4'])\n",
    "    if (i==221 or i==700 or i==1313):\n",
    "        f = 0\n",
    "        mesh = trimesh.load(mesh_file,force='mesh')\n",
    "        #view_mesh(mesh)\n",
    "        \n",
    "        # Curvature \n",
    "        data = discrete_gaussian_curvature_measure(mesh,mesh.vertices, 0.1)\n",
    "        local_weight = 0\n",
    "        global_weight = 1\n",
    "        scaler = MinMaxScaler()\n",
    "        norm_data = np.array(local_weight*data - global_weight*data).reshape(-1,1)\n",
    "        norm_data = scaler.fit_transform(norm_data)\n",
    "        norm_hist, _ = np.histogram(norm_data,bins=8)\n",
    "        curvature = norm_hist\n",
    "        norm = matplotlib.colors.Normalize(vmin=(local_weight*min(data))-(global_weight*40), vmax=(local_weight*max(data))+ (global_weight*30), clip=True)\n",
    "        mapper = cm.ScalarMappable(norm=norm, cmap=cm.turbo)\n",
    "        node_color = [(r, g, b) for r, g, b, a in mapper.to_rgba(data)]\n",
    "        mesh.visual.vertex_colors = node_color\n",
    "        #mesh.show()\n",
    "\n",
    "        # Scalar Features\n",
    "        pc_mesh = PointCloud(mesh.vertices).convex_hull\n",
    "        diameter = np.max(pc_mesh.bounds[1]-pc_mesh.bounds[0])\n",
    "        features.append(i)\n",
    "\n",
    "        normalized_area, f = standardize(mesh.area,f, mean_std)\n",
    "        features.append(normalized_area)\n",
    "\n",
    "        volume =  pc_mesh.volume\n",
    "        thresh = 0.00823\n",
    "        if (volume < thresh):\n",
    "            volume = thresh\n",
    "\n",
    "        normalized_volume, f = standardize(volume, f, mean_std)\n",
    "        features.append(normalized_volume)\n",
    "\n",
    "        compactness = (pc_mesh.area**3)/ (36* np.pi*(volume**2))\n",
    "        sphericity = 1/compactness\n",
    "\n",
    "        normalized_compactness, f = standardize(compactness, f, mean_std)\n",
    "        features.append(normalized_compactness)\n",
    "        normalized_sphericity, f = standardize(sphericity, f, mean_std)\n",
    "        features.append(normalized_sphericity)\n",
    "\n",
    "        features.append(diameter)\n",
    "        f+=1\n",
    "\n",
    "        rectangularity = volume / mesh.bounding_box.volume\n",
    "        normalized_rectangularity, f = standardize(rectangularity, f, mean_std)\n",
    "        features.append(normalized_rectangularity)\n",
    "\n",
    "        eccentricity  = abs(mesh.principal_inertia_components[0] / mesh.principal_inertia_components[2])\n",
    "        normalized_eccentricity, f = standardize(eccentricity, f, mean_std)\n",
    "        features.append(normalized_eccentricity)\n",
    "\n",
    "        normalzied_curvature = curvature/np.sum(curvature)\n",
    "        features.append(normalzied_curvature)\n",
    "\n",
    "        # Shape descriptors\n",
    "        A3 = []\n",
    "        D1 = []\n",
    "        D2 = []\n",
    "        D3 = []\n",
    "        D4 = []\n",
    "        v_bary = mesh.centroid\n",
    "        c = 0\n",
    "        for j in range (50000):\n",
    "            n1 = random.randint(0,len(mesh.vertices)-1)\n",
    "            n2 = random.randint(0,len(mesh.vertices)-1)\n",
    "            n3 = random.randint(0,len(mesh.vertices)-1)\n",
    "            n4 = random.randint(0,len(mesh.vertices)-1)\n",
    "\n",
    "            a = []\n",
    "            a.append(n1)\n",
    "            a.append(n2)\n",
    "            a.append(n3)\n",
    "            a.append(n4)\n",
    "            if(len(np.unique(a))!=len(a)):\n",
    "                j-=1\n",
    "                continue\n",
    "            v1 = mesh.vertices[n1] \n",
    "            v2 = mesh.vertices[n2] \n",
    "            v3 = mesh.vertices[n3]\n",
    "            v4 = mesh.vertices[n4]\n",
    "\n",
    "            # A3 Angle\n",
    "            vec1 = v2-v1\n",
    "            vec2 = v3-v1\n",
    "            vec3 = v4-v1\n",
    "\n",
    "            norm_v1 = np.linalg.norm(vec1)\n",
    "            norm_v2 = np.linalg.norm(vec2)\n",
    "            if ((norm_v1* norm_v2) ==0):\n",
    "                j-=1\n",
    "                continue\n",
    "            if math.isnan(np.dot(vec1,vec2) / (norm_v1* norm_v2) ):\n",
    "                j-=1\n",
    "                continue\n",
    "            angle = (np.rad2deg(np.arccos( np.dot(vec1,vec2) / (norm_v1* norm_v2) )))\n",
    "            if math.isnan(angle):\n",
    "                j-=1\n",
    "                continue\n",
    "            A3.append(angle)\n",
    "\n",
    "            distance = np.linalg.norm(v1-v_bary)\n",
    "            D1.append(distance)\n",
    "\n",
    "            distance_2 = np.linalg.norm(v1-v2)\n",
    "            D2.append(distance_2)\n",
    "\n",
    "            crosses = np.array([np.cross(vec1,vec2)])\n",
    "            area = (np.sum(crosses**2, axis=1)**.5) * .5\n",
    "            distance_3 = min(np.sum(area), 0.1)\n",
    "            D3.append(distance_3)\n",
    "\n",
    "            prod = np.linalg.norm( np.dot(np.cross(vec1,vec2),vec3))\n",
    "            volume = (1/6)*prod\n",
    "            cube_root = volume**(1/3)\n",
    "            D4.append(cube_root)\n",
    "\n",
    "        A3_descriptor, x = np.histogram(A3,bins=8)\n",
    "        normalzied_A3_descriptor = A3_descriptor/np.sum(A3_descriptor)\n",
    "        features.append(normalzied_A3_descriptor)\n",
    "\n",
    "        D1_descriptor, x = np.histogram(D1,bins=8)\n",
    "        normalzied_D1_descriptor = D1_descriptor/np.sum(D1_descriptor)\n",
    "        features.append(normalzied_D1_descriptor)            \n",
    "\n",
    "        D2_descriptor, x = np.histogram(D2,bins=8)\n",
    "        normalzied_D2_descriptor = D2_descriptor/np.sum(D2_descriptor)\n",
    "        features.append(normalzied_D2_descriptor)              \n",
    "\n",
    "        D3_descriptor, x = np.histogram(D3,bins=8)\n",
    "        normalzied_D3_descriptor = D3_descriptor/np.sum(D3_descriptor)\n",
    "        features.append(normalzied_D3_descriptor)             \n",
    "\n",
    "        D4_descriptor, x = np.histogram(D4,bins=8)\n",
    "        normalzied_D4_descriptor = D4_descriptor/np.sum(D4_descriptor)\n",
    "        features.append(normalzied_D4_descriptor)\n",
    "        \n",
    "        features_df.loc[len(features_df)] = features\n",
    "    \n",
    "        query = query = np.array(features_df.loc[0])\n",
    "        \n",
    "        pred_list = predict(query_database, query, sampled_min_max, sampled_mean_std, K)\n",
    "        print(i, pred_list)\n",
    "        #get_query(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeddb22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
